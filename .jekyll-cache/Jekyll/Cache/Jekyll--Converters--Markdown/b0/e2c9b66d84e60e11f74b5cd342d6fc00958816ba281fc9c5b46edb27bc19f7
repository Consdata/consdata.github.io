I"¤L<p><strong>Gdy robimy zakupy w internecie, czÄ™sto zdarza siÄ™, Å¼e przez kolejne dni pokazujÄ… nam siÄ™ propozycje produktÃ³w, podobnych do tych, ktÃ³re wczeÅ›niej oglÄ…daliÅ›my. Atrakcyjne ceny powodujÄ…, iÅ¼ czasem ulegamy presji reklamy, decydujemy siÄ™ na zapoznanie siÄ™ z ofertÄ… iâ€¦dokonujemy zakupu. Jak to siÄ™ dzieje, Å¼e przeglÄ…darka wie, co chcemy kupiÄ‡, zobaczyÄ‡ czy posÅ‚uchaÄ‡? Za to wszystko odpowiadajÄ… systemy rekomendacyjne.</strong></p>

<p><strong>Systemy rekomendacyjne</strong> widzimy wszÄ™dzie tam, gdzie uÅ¼ytkownik ma stycznoÅ›Ä‡ z ogromnymi katalogami danych, np. <strong>Amazon</strong> podpowiada nam, jakie produkty powinniÅ›my kupiÄ‡, <strong>Netflix</strong> - jakie filmy oglÄ…daÄ‡, a <strong>Spotify</strong> - ktÃ³re utwory na pewno nam siÄ™ spodobajÄ…. Wykorzystywane sÄ… przez coraz wiÄ™kszÄ… iloÅ›Ä‡ usÅ‚ug, a ich popularnoÅ›Ä‡ stale roÅ›nie. Odpowiada za to koncepcja <strong>â€œLong Tailâ€</strong>.</p>

<p>W 1988 roku brytyjski alpinista Joe Simpson napisaÅ‚ ksiÄ…Å¼kÄ™ pod tytuÅ‚em â€Touching the Voidâ€, w ktÃ³rej opisaÅ‚ swoje zmagania w peruwiaÅ„skich Alpach. Publikacja cieszyÅ‚a siÄ™ zainteresowaniem, wkrÃ³tce jednak zostaÅ‚aby zapomniana, gdyby nie Jon Krakauer, ktÃ³ry dekadÄ™ pÃ³Åºniej napisaÅ‚ â€Into Thin Airâ€, czyli kolejnÄ… pozycjÄ™ o wspinaczkowych starciach. Po jej wydaniu ksiÄ…Å¼ka Joe Simspona nagle wrÃ³ciÅ‚a do sprzedaÅ¼y, nastÄ…piÅ‚y dodruki, aby nadÄ…Å¼yÄ‡ za popytem. Co wiÄ™cej, przez czternaÅ›cie tygodni znajdowaÅ‚a siÄ™ na liÅ›cie bestsellerÃ³w NewYork Times i sprzedano jej dwukrotnie wiÄ™cej niÅ¼ dzieÅ‚o Krakauera! Dlaczego tak siÄ™ staÅ‚o? OtÃ³Å¼ Amazon zarekomendowaÅ‚ ksiÄ…Å¼kÄ™ â€Touching the Voidâ€ podczas zakupu â€Into Thin Airâ€, jako ksiÄ…Å¼kÄ™, ktÃ³ra rÃ³wnieÅ¼ moÅ¼e spodobaÄ‡ siÄ™ kupujÄ…cemu. Teoria Long Tail sugeruje, Å¼e na rynku internetowym sumaryczny dochÃ³d ze sprzedaÅ¼y pojedynczych towarÃ³w niszowych, moÅ¼e generowaÄ‡ wyÅ¼sze zyski, niÅ¼ oferowane masowo produkty popularne, tzw. bestsellery.</p>

<p>Najciekawszym rodzajem rekomendacji sÄ… te bazujÄ…ce na danych o konkretnych uÅ¼ytkownikach. MoÅ¼emy tu wyrÃ³Å¼niÄ‡ dwa podejÅ›cia:</p>

<ul>
  <li><strong>Content Based Filtering</strong>, ktÃ³ry opiera siÄ™ na cechach, typach produktÃ³w, szukajÄ…c podobnych do tych, ktÃ³re uÅ¼ytkownik juÅ¼ oceniÅ‚ pozytywnie lub kupiÅ‚,</li>
</ul>

<p><img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/1.jpg" alt="Content Based Filtering" /></p>

<ul>
  <li><strong>Collaborative Filtering</strong>, czyli rekomendacje na podstawie ocen i zakupÃ³w uÅ¼ytkownika. Gdy dwÃ³ch uÅ¼ytkownikÃ³w kupuje podobne produkty, moÅ¼emy stwierdziÄ‡, Å¼e majÄ… zbliÅ¼one upodobania i polecaÄ‡ im wzajemnie sprawdzone dla nich artykuÅ‚y.</li>
</ul>

<p><img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/2.jpg" alt="Collaborative Filtering" /></p>

<h2 id="collaborative-filtering--przykÅ‚ad-implementacji">Collaborative Filtering â€“ przykÅ‚ad implementacji</h2>
<p>Collaborative Filtering dzieli siÄ™ na jeszcze dwa rodzaje:</p>
<ul>
  <li><strong>Item-based</strong>, ktÃ³ry bazujÄ…c tylko na ocenach, wyszukuje podobne przedmioty i je rekomenduje,</li>
  <li><strong>User-based</strong>, ktÃ³rego przykÅ‚ad implementacji szerzej omÃ³wimy.</li>
</ul>

<p>Zasada jest prosta. WyobraÅºmy sobie, Å¼e mamy uÅ¼ytkownika X. Dla tego uÅ¼ytkownika znajdujemy grupÄ™ innych uÅ¼ytkownikÃ³w, ktÃ³rzy sÄ… do siebie podobni, np. zgodnie oceniajÄ… te same filmy. Jest to tzw. sÄ…siedztwo uÅ¼ytkownika X. W tej grupie znajdujemy zbiÃ³r filmÃ³w, ktÃ³re rÃ³wnieÅ¼ sÄ… przez niÄ… wysoko oceniane, a uÅ¼ytkownik X ich nie oglÄ…daÅ‚ i rekomendujemy mu je. Dane, z ktÃ³rych skorzystaÅ‚am, pochodzÄ… ze strony MovieLens. W zbiorze danych znajduje siÄ™ m.in. 100.000 ocen uÅ¼ytkownikÃ³w w skali 1-5.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">ratings_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'user_id'</span><span class="p">,</span> <span class="s">'movie_id'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">,</span> <span class="s">'timestamp'</span><span class="p">]</span>
<span class="n">ratings</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'u.data'</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">ratings_columns</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'latin-1'</span><span class="p">)</span>
<span class="n">ratings</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span> <span class="s">"timestamp"</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span> <span class="p">)</span>
<span class="k">print</span> <span class="n">ratings</span><span class="p">.</span><span class="n">shape</span>
<span class="n">ratings</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/3.jpg" alt="Wynik dziaÅ‚ania" /></p>

<p>Na podstawie tej tabelki utworzymy macierz ocen filmÃ³w userId x movieId.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">user_movies</span> <span class="o">=</span> <span class="n">ratings</span><span class="p">.</span><span class="n">pivot</span><span class="p">(</span> <span class="n">index</span><span class="o">=</span><span class="s">'user_id'</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s">'movie_id'</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="s">"rating"</span> <span class="p">).</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">user_movies</span><span class="p">.</span><span class="n">fillna</span><span class="p">(</span> <span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span> <span class="p">)</span>
<span class="n">user_movies</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">user_movies</span><span class="p">)</span>
<span class="k">print</span> <span class="n">user_movies</span><span class="p">.</span><span class="n">shape</span>
<span class="n">user_movies</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/4.jpg" alt="Wyniki" /></p>

<p>Kolejnym krokiem jest wyznaczenie n-tego sÄ…siedztwa uÅ¼ytkownika X, czyli grupy najbardziej podobnych mu osÃ³b. Aby to zrobiÄ‡, potrzebujemy miary podobieÅ„stwa miÄ™dzy uÅ¼ytkownikami, ktÃ³rych istnieje mnogoÅ›Ä‡, m.in. miarÄ™ cosinusowÄ…, wspÃ³Å‚czynnik Jaccarda. Ja uÅ¼yjÄ™ wspÃ³Å‚czynnika korelacji Pearsona. Miara ta mieÅ›ci siÄ™ w przedziale zamkniÄ™tym [-1, 1], gdzie 1 bÄ™dzie oznaczaÅ‚a stuprocentowe podobieÅ„stwo.</p>

<p><img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/5.jpg" alt="Wyniki" /></p>

<p>Nie pokuszÄ™ siÄ™ jednak o implementacjÄ™ tego wzoru, a wykorzystam gotowÄ… funkcjÄ™ z biblioteki SciPy.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="n">users_similarity</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">pairwise_distances</span><span class="p">(</span> <span class="n">user_movies</span><span class="p">.</span><span class="n">as_matrix</span><span class="p">(),</span> <span class="n">metric</span><span class="o">=</span><span class="s">"correlation"</span> <span class="p">)</span>
<span class="n">users_similarity_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span> <span class="n">users_similarity</span> <span class="p">)</span>
<span class="k">print</span> <span class="n">users_similarity</span><span class="p">.</span><span class="n">shape</span>
<span class="n">users_similarity_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/6.jpg" alt="Wyniki" /></p>

<p>OtrzymaliÅ›my macierz userId x userId z wyliczonymi wartoÅ›ciami podobieÅ„stwa miÄ™dzy kaÅ¼dym uÅ¼ytkownikiem. MoÅ¼emy teÅ¼ z niej zauwaÅ¼yÄ‡, Å¼e uÅ¼ytkownicy sÄ… najbardziej podobni doâ€¦ samych siebie (wartoÅ›Ä‡ 1 po przekÄ…tnej macierzy). Do dalszych obliczeÅ„ wypeÅ‚nilibyÅ›my przekÄ…tnÄ… macierzy zerami, aby nie zakÅ‚amywaÄ‡ wynikÃ³w. Tak to wyglÄ…da krok po kroku. Tak naprawdÄ™ Python uÅ‚atwia nam obliczenia jeszcze bardziej, oferujÄ…c metodÄ™ NearestNeighbors z biblioteki sklearn, w ktÃ³rej to moÅ¼emy podaÄ‡ np. wielkoÅ›Ä‡ szukanego sÄ…siedztwa, czy metodÄ™ obliczania podobieÅ„stwa.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="k">def</span> <span class="nf">find_neighborhood</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>

    <span class="n">model_knn</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">metric</span> <span class="o">=</span> <span class="s">"correlation"</span><span class="p">,</span> <span class="n">algorithm</span> <span class="o">=</span> <span class="s">"brute"</span><span class="p">)</span>
    <span class="n">model_knn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">user_movies</span><span class="p">)</span>
    <span class="n">distances</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">model_knn</span><span class="p">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">user_movies</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">user_id</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">similarities</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">distances</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">print</span> <span class="s">'{0} most similar users for user with id {1}:</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">user_id</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">.</span><span class="n">flatten</span><span class="p">())):</span>
        <span class="c1"># pomiÅ„, jeÅ›li ten sam uÅ¼ytkownik
</span>        <span class="k">if</span> <span class="n">indices</span><span class="p">.</span><span class="n">flatten</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span> <span class="o">==</span> <span class="n">user_id</span><span class="p">:</span>
            <span class="k">continue</span><span class="p">;</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span> <span class="s">'{0}: User {1}, with similarity of {2}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">indices</span><span class="p">.</span><span class="n">flatten</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">similarities</span><span class="p">.</span><span class="n">flatten</span><span class="p">()[</span><span class="n">i</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">similarities</span><span class="p">,</span><span class="n">indices</span>
</code></pre></div></div>
<p>PowyÅ¼sza funkcja posÅ‚uÅ¼y nam do wylistowania sÄ…siedztwa danego uÅ¼ytkownika. Przyjmuje ona id uÅ¼ytkownika, ktÃ³rego sÄ…siedztwa szukamy oraz jego rozmiar. WykorzystujÄ…c wspÃ³Å‚czynnik korelacji Pearsona, na podstawie naszej pierwszej tabelki z ocenami uÅ¼ytkownikÃ³w otrzymamy odlegÅ‚oÅ›ci miÄ™dzy uÅ¼ytkownikiem â€wejÅ›ciowymâ€ a kaÅ¼dym pozostaÅ‚ym oraz odpowiadajÄ…ce im id userÃ³w. NastÄ™pnie w pÄ™tli moÅ¼emy wylistowaÄ‡ sÄ…siedztwo uÅ¼ytkownika, pomijajÄ…c przy tym jego samego.
<img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/7.jpg" alt="Wyniki" />
NastÄ™pnym krokiem bÄ™dzie przywidywanie ocen uÅ¼ytkownika.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">def</span> <span class="nf">predict_rate</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">item_id</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">similarities</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">find_neighborhood</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">neighborhood_ratings</span> <span class="o">=</span><span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">.</span><span class="n">flatten</span><span class="p">())):</span>
        <span class="k">if</span> <span class="n">indices</span><span class="p">.</span><span class="n">flatten</span><span class="p">()[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span> <span class="o">==</span> <span class="n">user_id</span><span class="p">:</span>
            <span class="k">continue</span><span class="p">;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">neighborhood_ratings</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">user_movies</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">indices</span><span class="p">.</span><span class="n">flatten</span><span class="p">()[</span><span class="n">i</span><span class="p">],</span><span class="n">item_id</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>


    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">delete</span><span class="p">(</span><span class="n">indices</span><span class="p">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span> <span class="c1">#delete weight for input user
</span>    <span class="n">prediction</span> <span class="o">=</span> <span class="nb">round</span><span class="p">((</span><span class="n">neighborhood_ratings</span> <span class="o">*</span> <span class="n">weights</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">weights</span><span class="p">.</span><span class="nb">sum</span><span class="p">())</span>

    <span class="k">print</span> <span class="s">'</span><span class="se">\n</span><span class="s">Predicted rating for user {0} -&gt; item {1}: {2}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span><span class="n">item_id</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>
<p>Za pomocÄ… funkcji find_neighborhood znajdziemy dla niego sÄ…siedztwo n uÅ¼ytkownikÃ³w, ktÃ³rzy ocenili film, ktÃ³rego ocenÄ™ bÄ™dziemy przewidywaÄ‡. Z takÄ… wiedzÄ…, w pÄ™tli tworzymy listÄ™ ocen danego filmu przez podobnych mu uÅ¼ytkownikÃ³w. Jak teraz obliczyÄ‡ prawdopodobnÄ… ocenÄ™? Najprostszym z rozwiÄ…zaÅ„ jest policzenie Å›redniej ocen caÅ‚ego sÄ…siedztwa uÅ¼ytkownika dla tego filmu i zaprezentowaÄ‡ to jako nasze przewidywanie. Niestety to rozwiÄ…zanie ignoruje wartoÅ›Ä‡ podobieÅ„stwa miÄ™dzy uÅ¼ytkownikami, wiÄ™c lepszym podejÅ›ciem policzenie Å›redniej waÅ¼onej. Jako wagi przyjmiemy â€odlegÅ‚oÅ›ciâ€ miÄ™dzy uÅ¼ytkownikami, ktÃ³re zwrÃ³ciÅ‚a nam funkcja w zmiennej indices. OtrzymujÄ…c spodziewany oceny uÅ¼ytkownikÃ³w dla danych filmÃ³w, moÅ¼emy zarekomendowaÄ‡ mu listÄ™ filmÃ³w, ktÃ³re bÄ™dÄ… bliskie jego upodobaniom.
<img src="/assets/img/posts/2018-08-07-algorytmy-rekomendacyjne-przyklad-implementacji-w-pythonie/8.jpg" alt="Wyniki" /></p>

<h2 id="podsumowanie">Podsumowanie</h2>
<p>PowyÅ¼szy przykÅ‚ad implementacji jest oczywiÅ›cie bardzo podstawowym. DuÅ¼e portale korzystajÄ… raczej z hybrydowych rozwiÄ…zaÅ„, prÃ³bujÄ…c jak najbardziej trafnie oszacowaÄ‡ nasze upodobania. Ich metody rekomendacji bazujÄ… na tak duÅ¼ych danych i sÄ… tak czasochÅ‚onne, Å¼e rekomendacje nie sÄ… obliczane na bieÅ¼Ä…co, po kaÅ¼dej ocenie uÅ¼ytkownika, czy po kaÅ¼dym zakupie, a sÄ… uaktualniane raz na kilka dni.</p>
:ET